* STAT2008: Regression Modeling
* WK1
** L1
   
Characteristics of variables:
- level of measurement
- nominal - named categories
- ordinal - ordered categories
- interval
- ratio

Nominal and ordinal are discrete, ratios are continuous, and intervals use interval measurement
# You know what these are, you don't need to go through those again

** L2
*** Notation
Population: 
- random variables: X, Y, Y_1, Y_2, X_2
- paramters: \mu, \epsilon, \pi

Sample (observations/measurements):
- sample instances of random variables: x, y, y_1, x_1 

FOR THE EXAMPLE IN THE LECTURE

Data: (x_i,y_i) | i=1,2,3,...,n n=138

sample mean of y = $\frac{y_{1}+y_{2}+...+y_{n}}{n}$, or in more compact form:  $y\bar = \frac{\sum^{n}^{}_{}_{i=1}y_{i}}{n}$


sample variance of y: \Delta^{2}y or s^{2}y = $\frac{S_{y}_{y}}{n-1}$ | n-1 = degrees of freedom = $$\frac{1}{n-1}\sum_{{i=1}}^{n}(y_{i}-\bar{\mbox{y}})^{2}$$

unbiased point estimate of \delta^{2}y (population variance)

/we could do the same for x/

*** Central Limit Theorem
If we are sampling from a population with mean \mu y, and variance \delta^{2}y, then as n -> \infin the sampling distribution of the mean will approach: 
$$ N(y\mu,\frac{\delta^{2}^{}y}{n})$$

standard deviation of the sampling distribution is $\frac{y\delta}{\sqrt{n}}$

   _Confidence Intervals_

A 100(1-\alpha)% CI for y\mu in:
$\bar{\mbox{y}} \plusmn Z_{{\alpha/2}} . \frac{y\delta}{\sqrt{n}}$

1. point estimate
2. critical value from a standard distribution (model)
3. standard error

2 & 3 are the margin of error

But, in practise, we don't (usually) know \delta\mbox{y}! We estimate \delta\mbox{y} using \Delta\mbox{y} (the sample standard deviation)

** L3
   
* WK2
** L1: Simple Linear Regression Model
   
   _ORSENTOR_
Mean model: $E[Y|X]=\beta_{0}+\beta_{1}X_{i}$\\


$Y_{i}=\beta_{0}+\beta_{1}X_{i}+\epsilon_{i}$, $i=1,2,...,N$
# draw these graphs that he's putting up now, so that you can get all of the relevant information out of them and can put it in here

So how do we estimate oarsitnaorisetnaorsitenoariesntoarisentoairesntoiarst?
_Using *Method of Least Squares_

find b_0 & b_1 that minimise
(((INSERT FORMULA HERE FROM )))

To calculate b_0 & b_1 in practice we need means & variances of the $x$ & $y$ sample variables & we also need the covariance of X,Y:
- to estimate this in the sample we use _Sum of the Product of X&Y_
 $$\frac{S_{x,y}}{(n-1)} = 

*** Assumptions undrelying a simple linear regression model

General assumptions (applicable to most statisitcal models):
- that the sample is representative of the population of interest
- that the explanatory (x) variables are measured without error (or at least minimal error of $Y$) \rightarrow all the error is in the $Y$ direction (vertical on the earlier plots)
- that a model of the proposed form (e.g. a linear model) is appropriate

  
Model-specific assumptions:
- *Population*: $Y_{i}=\beta_{0}+\beta_{1}X_{i}+\epsilon_{i}$, $i=1,2,...,N$
- Deterministic model for the mean: $E[Y_{i}|X]=\beta_{0}+\beta_{1}X_{i}$
- stochastic model for variance: $\epsilon_{i}$
- Assumptions specific to this model are about \epsilon_i

** L2
ANOVA = Analysis of Variance 

The estimated variance model is detailed in the ANOVA table

_ANOVA Table_
| Source (of variability) | degrees of freedom | sum of squares | mean square | F statistic | P |
|-------------------------+--------------------+----------------+-------------+-------------+---|
| model/regression        | 1                  | SS_Reg = SS_Total+SS_error |             |             |   |
| error/residual          | n-2                | SS_error = $\epsilon ei^2$ | MS total = $\frac{SS_{error}}{n-2}=\Delta^{2}j$            |             |   |
|-------------------------+--------------------+----------------+-------------+-------------+---|
| Total                   | n - 1              | Syy = SS_Total | could calculate MS total = $\frac{SS_{Total}}{n-1}=\Delta^{2}j$ |             |   |

- Row 4 is equivalent to the Null model $Y=\beta_{0}+\epsilon$
- Row 2 is equivalent to the SLR model: $Y=\beta_{0}+\beta_{1}X+\epsilon$
  

Key estimate of the error variance \delta^2 is the MS error. To calculate this:
1. find
2. 

** L3
   
Conclusion: "The slope of the linear regression model relating average temparature anomalies to year is significantly positive \rightarrow temperatures have been nivreasing over time."

Finally, we need to assess the analysis and the results. Some questions follow:
1. Is the data we sued the best available to address the research question? (issue of the science)
2. Is the model a good fit? (is the moedl ont only apporpiriate, but also useful)

* WK3
** L1
aoeuaoeuaoeuaoeu
* WK4
** L1
* WK11
**  god fucking dammit end me
Model Selection
A "good" model is one whech we can use to address the research question, which may:
- involve certain variable, which we must include in the model, so we can observe and/or "control for" the effects of these variables
- other variables (included in the data) may also be included in the model, if they help to explain of sort of variation i.e. they turn out to be "significant"
- ultimately the research question may require some predictions; preferably predictions that hold validity
  Not iy have already chosen some scale for the variables in the model and a particular form for the model, we can then experiment with model that include other X variables in the data as predictors, as well as dorived variables (X^2, logX, interaction terms involving X, ...)
If we have K possible predictors, then the number of candidate models is O(2^k) <- ("of the order") <- as a minimum (as we can also allaw for different orders of the predictors)
i.e. k = 1, 2 possible models; k=10 > 1024 models
                               k=20, 2^20 > 1,048,576
For observational covariates (optional X's) we use *Principle of Parsimony* (Occam's Razor)
Of two simpler models, we will tend to prefer the simpler one (especially if there is no sig. difference between them)
